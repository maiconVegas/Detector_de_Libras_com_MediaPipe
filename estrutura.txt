.
├── dataset/              # Dados de treinamento e amostras de Libras
│   ├── letters/          # Imagens ou vídeos de gestos de letras
│   ├── gestures/         # Imagens ou vídeos de gestos como "sim", "cavalo", etc.
│   └── labels.csv        # Arquivo de rótulos (nomes dos gestos e letras)
│
├── models/               # Modelos treinados
│   ├── hand_model.pkl    # Modelo de detecção de letras
│   ├── gesture_model.pkl # Modelo de detecção de gestos
│
├── src/                  # Código fonte do projeto
│   ├── __init__.py       # Inicializador do pacote
│   ├── main.py           # Arquivo principal de execução do sistema
│   ├── hand_detection.py # Código para detecção de letras
│   ├── gesture_detection.py # Código para detecção de gestos
│   ├── utils.py          # Funções auxiliares
│   └── training.py       # Código para treinar modelos
│
├── notebooks/            # Notebooks para prototipação e experimentos
│   └── training.ipynb    # Notebook de treinamento de modelo
│
├── requirements.txt      # Lista de dependências do projeto
└── README.md             # Descrição do projeto e instruções




USEI A SEQUENCIA DE GESTOS PARA CAPTAR A LETRA, PORÉM ACHO QUE ESTA DANDO CERTO POIS TEM VARIOS MOVIMENTOS, PORÉM NÃO É TÃO PRECISO, ACHO QUE AQUELE DE CLICAR NA LETRA E FAZER O GESTO ACHO IDEAL POIS É CADA FOTO QUANDO CLICA NA LETRA. 